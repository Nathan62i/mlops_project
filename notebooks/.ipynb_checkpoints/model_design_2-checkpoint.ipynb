{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "629827f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935d3615",
   "metadata": {},
   "source": [
    "### Pr√©-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "149f5b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../../data/archive/train.csv')\n",
    "data_test = pd.read_csv('../../data/archive/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3355ed77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>film-url</th>\n",
       "      <th>review</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-135259/c...</td>\n",
       "      <td>Si vous cherchez du cin√©ma abrutissant √† tous ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-172430/c...</td>\n",
       "      <td>Trash, re-trash et re-re-trash...! Une horreur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-15105/cr...</td>\n",
       "      <td>Et si, dans les 5 premi√®res minutes du film, l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-188629/c...</td>\n",
       "      <td>Mon dieu ! Quelle m√©taphore fil√©e ! Je suis ab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-23514/cr...</td>\n",
       "      <td>Premier film de la saga Kozure Okami, \"Le Sabr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159995</th>\n",
       "      <td>159995</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-132387/c...</td>\n",
       "      <td>Un rythme bien trop lent et un Ashton Kutcher ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159996</th>\n",
       "      <td>159996</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-53313/cr...</td>\n",
       "      <td>Monsieur Duchovny vous √™tes aussi pi√®tre acteu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159997</th>\n",
       "      <td>159997</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-248258/c...</td>\n",
       "      <td>Compl√®tement diff√©rent des films de la s√©rie C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159998</th>\n",
       "      <td>159998</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-268731/c...</td>\n",
       "      <td>Alors franchement pour le moment c'est le meil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159999</th>\n",
       "      <td>159999</td>\n",
       "      <td>http://www.allocine.fr/film/fichefilm-188871/c...</td>\n",
       "      <td>Beur sur la ville r√©unit √† lui m√™me toutes les...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160000 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                           film-url  \\\n",
       "0                0  http://www.allocine.fr/film/fichefilm-135259/c...   \n",
       "1                1  http://www.allocine.fr/film/fichefilm-172430/c...   \n",
       "2                2  http://www.allocine.fr/film/fichefilm-15105/cr...   \n",
       "3                3  http://www.allocine.fr/film/fichefilm-188629/c...   \n",
       "4                4  http://www.allocine.fr/film/fichefilm-23514/cr...   \n",
       "...            ...                                                ...   \n",
       "159995      159995  http://www.allocine.fr/film/fichefilm-132387/c...   \n",
       "159996      159996  http://www.allocine.fr/film/fichefilm-53313/cr...   \n",
       "159997      159997  http://www.allocine.fr/film/fichefilm-248258/c...   \n",
       "159998      159998  http://www.allocine.fr/film/fichefilm-268731/c...   \n",
       "159999      159999  http://www.allocine.fr/film/fichefilm-188871/c...   \n",
       "\n",
       "                                                   review  polarity  \n",
       "0       Si vous cherchez du cin√©ma abrutissant √† tous ...         0  \n",
       "1       Trash, re-trash et re-re-trash...! Une horreur...         0  \n",
       "2       Et si, dans les 5 premi√®res minutes du film, l...         0  \n",
       "3       Mon dieu ! Quelle m√©taphore fil√©e ! Je suis ab...         0  \n",
       "4       Premier film de la saga Kozure Okami, \"Le Sabr...         1  \n",
       "...                                                   ...       ...  \n",
       "159995  Un rythme bien trop lent et un Ashton Kutcher ...         0  \n",
       "159996  Monsieur Duchovny vous √™tes aussi pi√®tre acteu...         0  \n",
       "159997  Compl√®tement diff√©rent des films de la s√©rie C...         1  \n",
       "159998  Alors franchement pour le moment c'est le meil...         1  \n",
       "159999  Beur sur la ville r√©unit √† lui m√™me toutes les...         0  \n",
       "\n",
       "[160000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32fed891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de la matrice de features pour train : (160000, 152189)\n",
      "Taille de la matrice de features pour test : (20000, 152189)\n",
      "Les premiers mots uniques extraits : ['00' '000' '000001ct' '0001' '000m' '000mots' '000volts' '001'\n",
      " '003023_21708_2' '005' '006' '007' '01' '015' '01h15' '01h30' '01h37'\n",
      " '01h40' '01h45' '01h49' '01h50' '01h57' '01min' '02' '02h10' '02h20'\n",
      " '02h45' '03' '031119' '04']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "french_stop_words = nlp.Defaults.stop_words\n",
    "\n",
    "# Initialisation de CountVectorizer avec les stop words\n",
    "vectorizer = CountVectorizer(stop_words=list(french_stop_words))\n",
    "\n",
    "# Application de CountVectorizer sur la colonne 'review'\n",
    "X_train = vectorizer.fit_transform(data_train['review'])\n",
    "X_test = vectorizer.transform(data_test['review'])\n",
    "\n",
    "y_train = data_train[\"polarity\"]\n",
    "y_test = data_test[\"polarity\"]\n",
    "\n",
    "print(\"Taille de la matrice de features pour train :\", X_train.shape)\n",
    "print(\"Taille de la matrice de features pour test :\", X_test.shape)\n",
    "print(\"Les premiers mots uniques extraits :\", vectorizer.get_feature_names_out()[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e425ae92",
   "metadata": {},
   "source": [
    "### Conception du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61eeaf90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La pr√©cision est de : 0.9103319888302823\n",
      "L'accuracy est de : 0.91715\n",
      "Le recall est de : 0.9176396997497915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score\n",
    "\n",
    "model_lr = LogisticRegression(max_iter = 10000)\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "prediction = model_lr.predict(X_test)\n",
    "\n",
    "precision = precision_score(y_test, prediction)\n",
    "accuracy = accuracy_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction)\n",
    "\n",
    "print(\"La pr√©cision est de :\", precision)\n",
    "print(\"L'accuracy est de :\", accuracy)\n",
    "print(\"Le recall est de :\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd9802",
   "metadata": {},
   "source": [
    "The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "\n",
    "The accuracy is the ratio of (values right predicted) / (number of total values)\n",
    "\n",
    "The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "\n",
    "Here for our case the metric to proritize seems to be the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30da8774",
   "metadata": {},
   "source": [
    "### Cr√©ation du pipeline scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe30e110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'accuracy de la pipeline est de : 0.91715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "estimators = [('vectorizer', CountVectorizer(stop_words=list(french_stop_words))), \n",
    "              ('model', LogisticRegression(max_iter = 10000))]\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "pipe.fit(data_train[\"review\"], y_train)\n",
    "pipe_prediction = pipe.predict(data_test[\"review\"])\n",
    "\n",
    "pipe_accuracy = accuracy_score(y_test, pipe_prediction)\n",
    "\n",
    "print(\"L'accuracy de la pipeline est de :\", pipe_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1867e619",
   "metadata": {},
   "source": [
    "### Logging des param√®tres MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99183477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "218183a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/493843891007736314', creation_time=1731418818145, experiment_id='493843891007736314', last_update_time=1731418818145, lifecycle_stage='active', name='pipeline_countVectorizer_lr', tags={}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "experiment_name = \"pipeline_countVectorizer_lr\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "363411ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "X_train = data_train[\"review\"]\n",
    "\n",
    "params = {\n",
    "    \"max_iter\" : 10000\n",
    "}\n",
    "\n",
    "input_example = pd.DataFrame(X_train, columns = [\"review\"])\n",
    "\n",
    "source_name = \"model_design_2.ipynb\"\n",
    "commit = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"]).strip().decode(\"utf-8\")\n",
    "branch = subprocess.check_output([\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\"]).strip().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad2383e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/12 15:36:36 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n",
      "2024/11/12 15:37:19 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n",
      "2024/11/12 15:38:31 WARNING mlflow.utils.requirements_utils: Found lz4 version (3.1.3+dfsg) contains a local version label (+dfsg). MLflow logged a pip requirement for this package as 'lz4==3.1.3' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2024/11/12 15:38:34 WARNING mlflow.utils.requirements_utils: Found lz4 version (3.1.3+dfsg) contains a local version label (+dfsg). MLflow logged a pip requirement for this package as 'lz4==3.1.3' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "Registered model 'logisticRegression' already exists. Creating a new version of this model...\n",
      "2024/11/12 15:38:37 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: logisticRegression, version 4\n",
      "Created version '4' of model 'logisticRegression'.\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  2.74it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n",
      "2024/11/12 15:39:21 INFO mlflow.tracking._tracking_service.client: üèÉ View run powerful-lynx-188 at: http://localhost:5000/#/experiments/493843891007736314/runs/8ec4c3cc7a8e4086962934411cc0f071.\n",
      "2024/11/12 15:39:21 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://localhost:5000/#/experiments/493843891007736314.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metric(\"test_accuracy\", pipe_accuracy)\n",
    "    mlflow.set_tag(\"Training Info\", \"Basic LR model with a CountVectorizer on pipeline\")\n",
    "    mlflow.set_tag(\"Preprocessing\", \"CountVectorizer\")\n",
    "    mlflow.set_tag(\"Algorithm\", \"Logistic Regression\")\n",
    "    \n",
    "    mlflow.set_tag(\"mlflow.source.name\", source_name)\n",
    "    mlflow.set_tag(\"mlflow.source.git.commit\", commit)\n",
    "    mlflow.set_tag(\"mlflow.source.git.branch\", branch)\n",
    "    \n",
    "    signature = infer_signature(X_train, pipe.predict(X_train))\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model = pipe,\n",
    "        artifact_path = \"train_review\",\n",
    "        signature = signature,\n",
    "        input_example = input_example,\n",
    "        registered_model_name = \"logisticRegression\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b55dce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
